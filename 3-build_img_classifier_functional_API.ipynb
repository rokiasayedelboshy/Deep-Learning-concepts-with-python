{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "lab03_build_img_classifier_functional_API.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIsTWNrUkHlz"
      },
      "source": [
        "# Introduction\n",
        "In this notebook, we are using the Keras API in Tensorflow 2.X to build an image classifier to recognize Handwritten digits using the Mnist data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9jkOW0BkFoO"
      },
      "source": [
        "# Loading Tensorflow and checking the version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whClKcLBkVLV",
        "outputId": "8383c299-c63b-47f4-eeb2-6bd37a0bcd31"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72OsafxTkePO"
      },
      "source": [
        "- If not installed, uncomment the following cell. \n",
        "- **PS:** using pip not conda as everything on colab is prepared for you (cuda)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL5w4z1qkfCn"
      },
      "source": [
        "#!pip install tensorflow==2.5.0 "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAUyfyCGkosR"
      },
      "source": [
        "# Data Loading and exploring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuoR7D5Oksiu",
        "outputId": "bf580512-ca7d-4407-bdf1-af0de58b2318"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(training_images, training_labels),(testing_images, testing_labels) = mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_Lgse1mloXb",
        "outputId": "925b536f-bec2-4af3-9a38-ad7b6edc9ce8"
      },
      "source": [
        "print(\"The number of training images is {}\".format(training_images.shape[0]))\n",
        "print(\"The number of testing images is {}\".format(testing_images.shape[0]))\n",
        "print(\"The shape of an image is {}X{}\".format(training_images.shape[1],\n",
        "                                              training_images.shape[2]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of training images is 60000\n",
            "The number of testing images is 10000\n",
            "The shape of an image is 28X28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJYUk6GrlGmp"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "np.set_printoptions(linewidth=200)\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "YboJdayulamy",
        "outputId": "3e494eb8-e4d9-469d-d151-8139190e428b"
      },
      "source": [
        "img_number = random.randint(0, training_images.shape[0])\n",
        "plt.imshow(training_images[img_number])\n",
        "print(training_labels[img_number])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsFk7rY5mWpo"
      },
      "source": [
        "All of the pixels values are between 0 and 255. If we are training a neural network, for various reasons it's easier that all values are between 0 and 1.\n",
        "\n",
        "This can be done using `normalizing`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb7d3LjcnB58"
      },
      "source": [
        "training_images  = training_images / 255.0\n",
        "testing_images = testing_images / 255.0"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXQ0kOROnflN"
      },
      "source": [
        "# Defining the model using **Sequential** API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9rkDIjdngXM"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56pQNcXJnoQu"
      },
      "source": [
        "model = Sequential([Flatten(input_shape=(28,28)), \n",
        "                    Dense(128, activation=tf.nn.relu), \n",
        "                    Dense(10, activation=tf.nn.softmax)])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlYUZ-Ag1_mm",
        "outputId": "411ee755-c5d6-4e6f-fe14-a6c3a2afb666"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmI9EO-8n9U4"
      },
      "source": [
        "Define the **optimizer** and the **loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVS9wyG9n_cE"
      },
      "source": [
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4m-li45MojR6"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94PtEBCwog6s",
        "outputId": "546bc456-715f-438b-a3d1-6cf1f1bf26bd"
      },
      "source": [
        "model.fit(training_images, training_labels, epochs=5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 2ms/step - loss: 0.2532 - accuracy: 0.9275\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1119 - accuracy: 0.9665\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0768 - accuracy: 0.9770\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0577 - accuracy: 0.9826\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0448 - accuracy: 0.9859\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdaa04c56d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qQXQdWnolTu"
      },
      "source": [
        "Evaluate the model on the test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC_Ium0nooci",
        "outputId": "002bcc2b-8ae2-4214-aa49-9490153b0236"
      },
      "source": [
        "evaluation = model.evaluate(testing_images, testing_labels)\n",
        "print(\"Accuracy on the testing images is {}\".format(evaluation[1]*100))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0734 - accuracy: 0.9755\n",
            "Accuracy on the testing images is 97.54999876022339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEGvoPkLyfcq"
      },
      "source": [
        "# Defining the model using **Functional** API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onLgl9jlyhyx"
      },
      "source": [
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RsBtjjgymem"
      },
      "source": [
        "inputs  = Input(shape=(28,28))\n",
        "x       = Flatten()(inputs)\n",
        "x       = Dense(128, activation=tf.nn.relu)(x)\n",
        "outputs = Dense(10, activation=tf.nn.softmax)(x)\n",
        "\n",
        "model_func = Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnEpk6i10HMd"
      },
      "source": [
        "model_func.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHvLRBU00K1q",
        "outputId": "cf39e08a-6792-4197-940f-3ebb549f644c"
      },
      "source": [
        "model_func.fit(training_images, training_labels, epochs=5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2617 - accuracy: 0.9249\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1151 - accuracy: 0.9651\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0786 - accuracy: 0.9761\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0603 - accuracy: 0.9815\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0458 - accuracy: 0.9858\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdaa02b6190>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWXUQ4tS0Pe2",
        "outputId": "c2a391ce-355b-4aeb-d0aa-f262598098cf"
      },
      "source": [
        "evaluation = model_func.evaluate(testing_images, testing_labels)\n",
        "print(\"Accuracy on the testing images is {}\".format(evaluation[1]*100))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0796 - accuracy: 0.9759\n",
            "Accuracy on the testing images is 97.58999943733215\n"
          ]
        }
      ]
    }
  ]
}