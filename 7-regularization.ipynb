{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "lab08_regularization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIsTWNrUkHlz"
      },
      "source": [
        "# Introduction\n",
        "In this notebook, we are using the Keras API in Tensorflow 2.X to build an image classifier to recognize Handwritten digits using the Mnist data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9jkOW0BkFoO"
      },
      "source": [
        "# Loading Tensorflow and checking the version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whClKcLBkVLV",
        "outputId": "53b3661b-f149-4310-c3a2-a7590cec2579"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72OsafxTkePO"
      },
      "source": [
        "- If not installed, uncomment the following cell. \n",
        "- **PS:** using pip not conda as everything on colab is prepared for you (cuda)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL5w4z1qkfCn"
      },
      "source": [
        "#!pip install tensorflow==2.5.0 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAUyfyCGkosR"
      },
      "source": [
        "# Data Loading and exploring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuoR7D5Oksiu",
        "outputId": "b34f7c21-2eaf-492c-de64-9625e3b0f632"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(training_images, training_labels),(testing_images, testing_labels) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_Lgse1mloXb",
        "outputId": "d448a38b-0ab7-4c4e-9b12-bbadf60323a4"
      },
      "source": [
        "print(\"The number of training images is {}\".format(training_images.shape[0]))\n",
        "print(\"The number of testing images is {}\".format(testing_images.shape[0]))\n",
        "print(\"The shape of an image is {}X{}\".format(training_images.shape[1],\n",
        "                                              training_images.shape[2]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of training images is 60000\n",
            "The number of testing images is 10000\n",
            "The shape of an image is 28X28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJYUk6GrlGmp"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "np.set_printoptions(linewidth=200)\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "YboJdayulamy",
        "outputId": "5a13f061-1432-483b-dc5c-21bf6dd07fcd"
      },
      "source": [
        "img_number = random.randint(0, training_images.shape[0])\n",
        "plt.imshow(training_images[img_number])\n",
        "print(training_labels[img_number])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsFk7rY5mWpo"
      },
      "source": [
        "All of the pixels values are between 0 and 255. If we are training a neural network, for various reasons it's easier that all values are between 0 and 1.\n",
        "\n",
        "This can be done using `normalizing`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb7d3LjcnB58"
      },
      "source": [
        "training_images  = training_images / 255.0\n",
        "testing_images = testing_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXQ0kOROnflN"
      },
      "source": [
        "# Defining the model using **Sequential** API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9rkDIjdngXM"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56pQNcXJnoQu"
      },
      "source": [
        "model = Sequential([Flatten(input_shape=(28,28)), \n",
        "                    Dense(128, activation=tf.nn.relu, kernel_regularizer=regularizers.l2(0.001)), \n",
        "                    Dense(10, activation=tf.nn.softmax)])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5WNp4Wq2GHC",
        "outputId": "ab3d3727-f8a2-4196-bb94-165ff9961c4e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_5 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmI9EO-8n9U4"
      },
      "source": [
        "Define the **optimizer** and the **loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVS9wyG9n_cE"
      },
      "source": [
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4m-li45MojR6"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94PtEBCwog6s",
        "outputId": "2cd37892-df97-4749-adc5-b0e5ce01ec2a"
      },
      "source": [
        "model.fit(training_images, training_labels, epochs=5, validation_split=0.15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1594/1594 [==============================] - 9s 4ms/step - loss: 0.4144 - accuracy: 0.9061 - val_loss: 0.2697 - val_accuracy: 0.9444\n",
            "Epoch 2/5\n",
            "1594/1594 [==============================] - 6s 3ms/step - loss: 0.2590 - accuracy: 0.9472 - val_loss: 0.2139 - val_accuracy: 0.9609\n",
            "Epoch 3/5\n",
            "1594/1594 [==============================] - 6s 3ms/step - loss: 0.2203 - accuracy: 0.9580 - val_loss: 0.2169 - val_accuracy: 0.9553\n",
            "Epoch 4/5\n",
            "1594/1594 [==============================] - 6s 3ms/step - loss: 0.2000 - accuracy: 0.9620 - val_loss: 0.1870 - val_accuracy: 0.9652\n",
            "Epoch 5/5\n",
            "1594/1594 [==============================] - 6s 4ms/step - loss: 0.1859 - accuracy: 0.9659 - val_loss: 0.1827 - val_accuracy: 0.9671\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4bb0182c10>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qQXQdWnolTu"
      },
      "source": [
        "Evaluate the model on the test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC_Ium0nooci",
        "outputId": "bcce9040-32c3-4283-e4e8-2328ae47e6e5"
      },
      "source": [
        "evaluation = model.evaluate(testing_images, testing_labels)\n",
        "print(\"Accuracy on the testing images is {}\".format(evaluation[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0809 - accuracy: 0.9756\n",
            "Accuracy on the testing images is 97.5600004196167\n"
          ]
        }
      ]
    }
  ]
}